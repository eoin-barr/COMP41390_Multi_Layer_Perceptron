# COMP41390 Multi-Layer Perceptron Assignment

A Multi-Layer Perceptron (MLP) is a supplement of a feed forward neural network and consists of three types of units â€“ input unit, output unit, and hidden unit. The aim of this assignment was to construct, train, and test an MLP on a range of problems including XOR, Sin, and a letter recognition task. The MLP created in this assignment had two layers and was required to be able to handle a variable number of input, hidden, and output units, implement different types of units (e.g. sigmoidal, tanh, softmax), initialise small random value weights, predict outputs corresponding to the input vector, and implement learning by backpropagation. Testing consisted of tuning the hyperparameters of the MLPs trained on the different problems and noting any insights gained from the changing of these hyperparameters.

The MLP successfully generalized to each of the tasks and achieved accuracies of 99% (XOR), 96% (Sin), and 88% (letter recognition task). If I had access to greater amounts of compute, both the Sin and letter recognition tasks could also have reached 99% accuracy.

## Errors and Accuracies

### XOR

![XOR](https://res.cloudinary.com/dk0r9bcxy/image/upload/v1673478664/portfolio-website/XOR_u1cdjw.png)

### Sin

![XOR](https://res.cloudinary.com/dk0r9bcxy/image/upload/v1673478664/portfolio-website/SIN_bqf2a1.png)

### Letter Recognition

![XOR](https://res.cloudinary.com/dk0r9bcxy/image/upload/v1673478664/portfolio-website/letter_cb9of2.png)
